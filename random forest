import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from matplotlib import pyplot
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error
df_=pd.read_csv("C:\\Users\\User\\Desktop\\dataset2.csv")
df=df_.copy()
df.head()
X = df.drop('tensile_strength', axis=1)
y = df['tensile_strength']
df.head()
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
X_train.shape
(69, 5)
rf_model = RandomForestRegressor()
rf_model.fit(X_train, y_train)


y_pred = rf_model.predict(X_train)

rf_model=RandomForestRegressor(random_state=42)
rf_model.fit(X_train,y_train)
y_pred = rf_model.predict(X_train)
r2 = r2_score(y_train, y_pred)
print("r2trainrf :" + str(r2))
y_pred = rf_model.predict(X_test)
print(y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
rf_params={"max_depth":list(range(1,4)),
           "max_features":[1,2,3,4],
          "n_estimators":[30,100]}
rf_model=RandomForestRegressor(random_state=42)
rf_cv_model=GridSearchCV(rf_model,
                        rf_params,
                        cv=10,
                        n_jobs=-1)

rf_cv_model.fit(X_train,y_train)

print("best param", rf_cv_model.best_params_)
rf_tuned=RandomForestRegressor(max_depth= 1, max_features= 1, n_estimators=100 )
rf_tuned.fit(X_train,y_train)
Importance=pd.DataFrame({"Importance":rf_tuned.feature_importances_*100},
                       index=X_train.columns)
Importance.sort_values(by="Importance",
                      axis=0,
                      ascending=True).plot(kind="barh",color="g")
sorted_data = Importance.sort_values(by="Importance", axis=0, ascending=True)
ax = sorted_data.plot(kind="barh", color="b")
ax.set_xlabel("Importance/ %")
ax.set_ylabel("Features")
mae = mean_absolute_error(y_test, y_pred)
print("MAE RF değeri:", mae)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("rmse :" + str(rmse))
R2 = r2_score(y_test, y_pred)
plt.show()
sns.regplot(y_test, y_pred, color='b', label=f"RMSE: {rmse:.2f}, R2: {R2:.2f}")
plt.xlabel('Test Values of T.S. MPa')
plt.ylabel('Predicted Values of T.S. MPa')
plt.legend()
plt.show()
a = [210, 50, 0.1, 60]
a = np.array(a) # convert to a numpy array
a = np.expand_dims(a, 0) # change shape from (8,) to (1,8)
rf_tuned.predict(a)
print("pred rf değeri:", rf_tuned.predict(a))
plt.title('OLS')
plt.xlabel('True Values')
plt.ylabel('Prediction')
plt.legend()
plt.show()
df = pd.DataFrame({"True values":y_test, "Prediction":y_pred}, index=X_test.index)
df.sort_index(inplace=True)
plt.scatter(df.index, df["True values"], marker="o", label="Test values")
plt.plot(df.index, df["Prediction"], color="r", label="Prediction")
plt.xlabel("Index")
plt.ylabel("Values")
plt.legend()
plt.show()
cv_results = cross_val_score(rf_tuned, X_train, y_train, cv=10, n_jobs=-1,)
scoring = ['accuracy', 'precision']
print("Accuracy score by cross-validation", cv_results)
print(np.mean(cross_val_score(rf_tuned, X_train, y_train, cv=10)))
print("y_pred list", y_pred)
